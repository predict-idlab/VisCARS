{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "going-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grakel\n",
    "from grakel.kernels import WeisfeilerLehman, VertexHistogram, ShortestPath, SubgraphMatching\n",
    "import json\n",
    "import os\n",
    "from rdflib import Graph\n",
    "from rdflib.extras.external_graph_libs import rdflib_to_networkx_digraph\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTPUT_DIR = '/home/pieter/Documents/ugent/phd/projects/PreDICT/PROTEGO/datasets/data/output/patients'\n",
    "BASE_DIR = 'benchmarks/DASHB'\n",
    "\n",
    "PATIENT_TEMPLATE = 'http://example.com/tx/patients/{pid}'\n",
    "\n",
    "G_nx = []\n",
    "patients = []\n",
    "for graph_f in os.listdir(INTPUT_DIR):\n",
    "    if graph_f.endswith('.ttl'):\n",
    "        graph = Graph()\n",
    "        graph.parse(os.path.join(INTPUT_DIR, graph_f), format='turtle')\n",
    "        \n",
    "        networkx_graph = rdflib_to_networkx_digraph(graph, edge_attrs=lambda s, p, o: {'label': p})\n",
    "        # Add node labels\n",
    "        for id_, data in networkx_graph.nodes(data=True):\n",
    "            data['label'] = id_\n",
    "            \n",
    "        G_nx.append(networkx_graph)\n",
    "        patients.append(PATIENT_TEMPLATE.format(pid=graph_f.split('.')[0]))\n",
    "        \n",
    "graphs = list(grakel.utils.graph_from_networkx(G_nx, node_labels_tag='label', edge_labels_tag='label', edge_weight_tag='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biological-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gk = ShortestPath(normalize=True)\n",
    "\n",
    "# gk.fit_transform(graphs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premium-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities = gk.transform(graphs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities_ = {}\n",
    "# for idx, sim in enumerate(similarities):\n",
    "#     similarities_[patients[idx + 1]] = sim\n",
    "\n",
    "# sorted_similarities = sorted(similarities_.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(sorted_similarities[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conventional-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gk = SubgraphMatching(with_labels=False, normalize=True)\n",
    "\n",
    "# gk.fit_transform(graphs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smoking-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simularities = gk.transform(graphs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ysig.github.io/GraKeL/0.1a8/auto_examples/document_retrieval_example.html\n",
    "\n",
    "# Initialize Weisfeiler-Lehman subtree kernel\n",
    "# gk = WeisfeilerLehman(n_iter=2, normalize=True, base_graph_kernel=VertexHistogram)\n",
    "\n",
    "# print(\"Computing similarities\\n\")\n",
    "# t0 = time.time()\n",
    "\n",
    "# gk.fit(graphs[:1])\n",
    "# similarities = gk.transform(graphs[1:])\n",
    "\n",
    "# print(\"done in %0.3fs\\n\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "suspended-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities_ = {}\n",
    "# for idx, sim in enumerate(similarities):\n",
    "#     similarities_[patients[idx + 1]] = sim\n",
    "\n",
    "# sorted_similarities = sorted(similarities_.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(sorted_similarities[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "invalid-worship",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 282/282 [01:22<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run for all patients\n",
    "similarities = {}\n",
    "for idx, pid in enumerate(tqdm(patients)):\n",
    "    gk = WeisfeilerLehman(n_iter=2, normalize=True, base_graph_kernel=VertexHistogram)\n",
    "    check = gk.fit_transform([graphs[idx]])[0]\n",
    "    \n",
    "    assert (check == 1)\n",
    "    \n",
    "    similarities[pid] = {}\n",
    "    for idx_, pid_ in enumerate(patients):\n",
    "        if pid == pid_:\n",
    "            similarities[pid][pid_] = float(check)\n",
    "        if pid_ in similarities.keys():\n",
    "            similarities[pid][pid_] = similarities[pid_][pid]\n",
    "        else:\n",
    "            similarities[pid][pid_] = float(gk.transform([graphs[idx_]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "traditional-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(BASE_DIR, 'results', 'WeisfeilerLehman.json'), 'w') as output_f:\n",
    "    output_f.write(json.dumps(similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-twins",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
